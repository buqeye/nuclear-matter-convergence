{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gsum as gm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from stats_utils import *\n",
    "from matter import *\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['text.usetex'] = True\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "mpl.rc('savefig', transparent=False, bbox='tight', pad_inches=0.05, format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Nuclear Matter Results (Refactored)\n",
    "\n",
    "A much cleaner version of the other notebook. It can be easily extended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/all_matter_data.csv')\n",
    "# Convert differences to total prediction at each MBPT order\n",
    "mbpt_orders = ['Kin', 'MBPT_HF', 'MBPT_2', 'MBPT_3', 'MBPT_4']\n",
    "df[mbpt_orders] = df[mbpt_orders].apply(np.cumsum, axis=1)\n",
    "# 'total' is now unnecessary. Remove it.\n",
    "df.pop('total');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define all of the parameters of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = np.array([0, 2, 3, 4])\n",
    "body = 'NN-only'\n",
    "# body = 'NN+3N'\n",
    "Lambda = 500\n",
    "fits = {450: [1, 7], 500: [4, 10]}\n",
    "train1 = slice(None, None, 5)\n",
    "valid1 = slice(2, None, 5)\n",
    "# valid1 = np.array([i % 5 != 0 for i in range(len())])\n",
    "[fit_n2lo, fit_n3lo] = fits[Lambda]\n",
    "\n",
    "savefigs = True\n",
    "\n",
    "Lb = 600\n",
    "\n",
    "breakdown_min = 300\n",
    "breakdown_max = 1000\n",
    "breakdown_num = 100\n",
    "Lb_vals = np.linspace(breakdown_min, breakdown_max, breakdown_num)\n",
    "Lb_logprior_vals = Lb_logprior(Lb_vals)\n",
    "\n",
    "ls_min = 0.1\n",
    "ls_max = 1.5\n",
    "ls_num = 50\n",
    "ls_vals = np.linspace(ls_min, ls_max, ls_num)\n",
    "\n",
    "kernel1 = RBF(length_scale=1, length_scale_bounds=(5e-2, 4)) + \\\n",
    "    WhiteKernel(noise_level=1e-10, noise_level_bounds='fixed')\n",
    "kernel1_theta = kernel1.theta\n",
    "ref1 = 16\n",
    "\n",
    "hyperparams = dict(\n",
    "    center=0,\n",
    "    disp=0,\n",
    "    df=5,\n",
    "    scale=1\n",
    ")\n",
    "\n",
    "\n",
    "mask_fit = np.isin(df['fit'], fits[Lambda]) | np.isnan(df['fit'])\n",
    "\n",
    "mask1 = \\\n",
    "    (df['Body'] == body) & \\\n",
    "    mask_fit & \\\n",
    "    (df['Lambda'] == Lambda)\n",
    "\n",
    "\n",
    "# df_fit = df[mask_fit]\n",
    "df_n = df[mask1 & (df['x'] == 0)]\n",
    "df_s = df[mask1 & (df['x'] == 0.5)]\n",
    "\n",
    "kf_n = df_n[df_n['OrderEFT'] == 'LO']['kf'].values\n",
    "kf_s = df_s[df_s['OrderEFT'] == 'LO']['kf'].values\n",
    "density = df_n[df_n['OrderEFT'] == 'LO']['n'].values\n",
    "kf_d = kf_n.copy()\n",
    "\n",
    "# valid1 = np.arange(len(kf_n)) % 5 != 0\n",
    "\n",
    "Kf_n = kf_n[:, None]\n",
    "Kf_s = kf_s[:, None]\n",
    "Kf_d = kf_d[:, None]\n",
    "\n",
    "y1_n = np.array([df_n[df_n['OrderEFT'] == order]['MBPT_4'].values for order in df_n['OrderEFT'].unique()]).T\n",
    "y1_s = np.array([df_s[df_s['OrderEFT'] == order]['MBPT_4'].values for order in df_s['OrderEFT'].unique()]).T\n",
    "y1_d = y1_n - y1_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These analysis objects will contain all the observable-specific info and know how to make various plots.\n",
    "The plots will save with informative image names and avoid a cluttered namespace. As we start varying more parameters, we should make sure that each important variable is reflected in the figure names, so that we don't overwrite images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_n = MatterConvergenceAnalysis(\n",
    "    X=Kf_n, y=y1_n, orders=orders, train=train1, valid=valid1, ref=ref1, ratio='kf', density=density,\n",
    "    kernel=kernel1, system='neutron', fit_n2lo=fit_n2lo, fit_n3lo=fit_n3lo, Lambda=Lambda,\n",
    "    body=body, savefigs=savefigs, **hyperparams\n",
    ")\n",
    "analysis_s = MatterConvergenceAnalysis(\n",
    "    X=Kf_s, y=y1_s, orders=orders, train=train1, valid=valid1, ref=ref1, ratio='kf', density=density,\n",
    "    kernel=kernel1, system='symmetric', fit_n2lo=fit_n2lo, fit_n3lo=fit_n3lo, Lambda=Lambda,\n",
    "    body=body, savefigs=savefigs, **hyperparams\n",
    ")\n",
    "analysis_d = MatterConvergenceAnalysis(\n",
    "    X=Kf_d, y=y1_d, orders=orders, train=train1, valid=valid1, ref=ref1, ratio='kf', density=density,\n",
    "    kernel=kernel1, system='difference', fit_n2lo=fit_n2lo, fit_n3lo=fit_n3lo, Lambda=Lambda,\n",
    "    body=body, savefigs=savefigs, **hyperparams\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can take a while if a large breakdown/ls grid is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_n.setup_posteriors(\n",
    "    breakdown_min=breakdown_min, breakdown_max=breakdown_max, breakdown_num=breakdown_num,\n",
    "    ls_min=ls_min, ls_max=ls_max, ls_num=ls_num,\n",
    "    max_idx=[2, 3], logprior=None\n",
    ")\n",
    "analysis_s.setup_posteriors(\n",
    "    breakdown_min=breakdown_min, breakdown_max=breakdown_max, breakdown_num=breakdown_num,\n",
    "    ls_min=ls_min, ls_max=ls_max, ls_num=ls_num,\n",
    "    max_idx=[2, 3], logprior=None\n",
    ")\n",
    "analysis_d.setup_posteriors(\n",
    "    breakdown_min=breakdown_min, breakdown_max=breakdown_max, breakdown_num=breakdown_num,\n",
    "    ls_min=ls_min, ls_max=ls_max, ls_num=ls_num,\n",
    "    max_idx=[2, 3], logprior=None\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame that holds the $\\Lambda_b$ pdf for all observables put together. Assume they are independent, so they multiply. Also, we assumed a constant prior above, so we don't need to worry about accidentally overcounting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Lb_pdf_all = analysis_n.df_breakdown.copy()\n",
    "df_Lb_pdf_all['pdf'] = analysis_n.df_breakdown['pdf'] * analysis_s.df_breakdown['pdf'] * analysis_d.df_breakdown['pdf']\n",
    "df_Lb_pdf_all['system'] = 'All'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_str(d):\n",
    "    s = ''\n",
    "    for key, value in d.items():\n",
    "        s += f'{key}-{value}_'\n",
    "    s = s.replace('.', 'p')\n",
    "    return s[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the plot of all their pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.4, 4.4))\n",
    "df_Lb_pdf = pd.concat([analysis_n.df_breakdown, analysis_s.df_breakdown, analysis_d.df_breakdown, df_Lb_pdf_all])\n",
    "ax = pdfplot(\n",
    "    x=r'$\\Lambda_b$ (MeV)', y='system', pdf='pdf', data=df_Lb_pdf, hue='Order',\n",
    "    order=[r'$E/N$', r'$E/A$', r'$S_2$', 'All'], hue_order=[r'N$^2$LO', r'N$^3$LO'], cut=1e-2, linewidth=1,\n",
    "        palette=\"coolwarm\", saturation=1., ax=ax, margin=0.3,\n",
    ")\n",
    "ax.set_xlim(0, 1200)\n",
    "ax.set_xticks([0, 300, 600, 900, 1200])\n",
    "ax.grid(axis='x')\n",
    "ax.set_axisbelow(True)\n",
    "if savefigs:\n",
    "    fig.savefig(\n",
    "        analysis_n.figure_name(\n",
    "            'Lb_pdfs_', breakdown=(breakdown_min, breakdown_max, breakdown_num), include_system=False,\n",
    "            ls=(ls_min, ls_max, ls_num),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now one for the marginal length scale pdfs. A common length scale for all observables probably isn't necessary, so don't compute an \"All\" pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ls_pdf = pd.concat([analysis_n.df_ls, analysis_s.df_ls, analysis_d.df_ls])\n",
    "ax = pdfplot(\n",
    "    x=r'$\\ell$ (fm$^{-1}$)', y='system', pdf='pdf', data=df_ls_pdf, hue='Order',\n",
    "    order=[r'$E/N$', r'$E/A$', r'$S_2$'], hue_order=[r'N$^2$LO', r'N$^3$LO'], cut=1e-2, linewidth=1.,\n",
    "        palette=\"coolwarm\", saturation=1., ax=None, margin=0.3,\n",
    ")\n",
    "ax.set_xticks([0, 0.5, 1.]);\n",
    "ax.grid(axis='x');\n",
    "ax.set_axisbelow(True)\n",
    "if savefigs:\n",
    "    fig.savefig(\n",
    "        analysis_n.figure_name(\n",
    "            'ls_pdfs_', breakdown=(breakdown_min, breakdown_max, breakdown_num), include_system=False,\n",
    "            ls=(ls_min, ls_max, ls_num),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analysis_n.plot_joint_breakdown_ls(max_idx=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analysis_s.plot_joint_breakdown_ls(max_idx=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analysis_d.plot_joint_breakdown_ls(max_idx=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analysis_n.plot_coeff_diagnostics(breakdown=Lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analysis_n.plot_coeff_diagnostics(breakdown=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's clearly some noise below, we should include it in the kernel. Discuss with Christian about the precision of his calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analysis_s.plot_coeff_diagnostics(breakdown=Lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analysis_s.plot_coeff_diagnostics(breakdown=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analysis_d.plot_coeff_diagnostics(breakdown=Lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = analysis_d.plot_coeff_diagnostics(breakdown=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gsum-env] *",
   "language": "python",
   "name": "conda-env-gsum-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
